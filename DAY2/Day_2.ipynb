{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xya39vqNnQcM",
        "outputId": "537aa5b0-21dc-4ec3-9056-9b5d2c3ffaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.3.0 in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-google-genai==2.0.2 in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: google-generativeai==0.8.2 in /usr/local/lib/python3.12/dist-packages (0.8.2)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (3.13.2)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (0.1.147)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.0) (8.5.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.26.1)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.22.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai==0.8.2) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (4.9.1)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
            "  Using cached langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.0)\n",
            "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.77-py3-none-any.whl.metadata (3.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting openai<2.0.0,>=1.104.2 (from langchain-openai)\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.73-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Using cached langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.20-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.0) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai==0.8.2) (3.2.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.2) (0.6.1)\n",
            "Downloading langchain_openai-0.3.19-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, langchain-openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.8.1\n",
            "    Uninstalling openai-2.8.1:\n",
            "      Successfully uninstalled openai-2.8.1\n",
            "Successfully installed langchain-openai-0.3.19 openai-1.109.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.0 langchain-google-genai==2.0.2 google-generativeai==0.8.2 langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai==0.8.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_GDQwg_nfk3",
        "outputId": "db17ebdb-1a3b-4b82-804b-493c5b3b9536"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai==0.8.2 in /usr/local/lib/python3.12/dist-packages (0.8.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.2) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai==0.8.2) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai==0.8.2) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai==0.8.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai==0.8.2) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai==0.8.2) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai==0.8.2) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.2) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "U19fL2u-ogSp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- API Key Setup ---\n",
        "# Load environment variables (assumes using Colab Secrets or a .env file)\n",
        "# If using Colab Secrets, click the key icon on the left panel.\n",
        "# Variables must be named GEMINI_API_KEY.\n",
        "\n",
        "# Get API key from environment variable\n",
        "\n",
        "gemini_api_key = userdata.get(\"DAY1\")\n",
        "if not gemini_api_key:\n",
        "    print(\"Warning: GEMINI_API_KEY not found. Gemini model will not run.\")"
      ],
      "metadata": {
        "id": "CeGYqz2moi4O"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Model Initialization ---\n",
        "# Using gemini-2.5-flash for a highly performant and cost-effective alternative\n",
        "gemini_model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-lite-001\",\n",
        "    google_api_key=gemini_api_key,\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "print(\"Setup complete. Gemini model initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmpQIcLIoqR8",
        "outputId": "d6a24366-a246-4e07-ff7f-9af79516c207"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Gemini model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"\"\"\n",
        "A farmer has 17 goats. All but 9 run away. How many goats are left?\n",
        "\"\"\"\n",
        "\n",
        "# --- Standard Prompt  ---\n",
        "standard_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"user\", \"{query}\")\n",
        "])\n",
        "\n",
        "chain_standard = standard_prompt | gemini_model | StrOutputParser()\n",
        "print(\"--- GPT Standard Response ---\")\n",
        "print(chain_standard.invoke({\"query\": user_query}))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aay9GcvvoyK7",
        "outputId": "e50a3b20-4cec-4976-cc9e-2085b3b81e3c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- GPT Standard Response ---\n",
            "If all but 9 goats run away, that means 9 goats are left.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Chain of Thought (CoT) Prompt (Reasoning) ---\n",
        "cot_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"user\", \"Let's think step by step to find the correct answer. {query}\")\n",
        "])\n",
        "chain_cot = cot_prompt | gemini_model | StrOutputParser()\n",
        "print(\"\\n--- GPT-4o CoT Response (Correct) ---\")\n",
        "print(chain_cot.invoke({\"query\": user_query}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z19g210Lo1IK",
        "outputId": "a876b42a-f60d-418d-a0d3-3764ea2e1b21"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GPT-4o CoT Response (Correct) ---\n",
            "Here's how to solve the problem:\n",
            "\n",
            "*   The problem states \"All but 9 run away.\"\n",
            "*   This means 9 goats did *not* run away and are still there.\n",
            "\n",
            "Answer: 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 1 : Write a blog post"
      ],
      "metadata": {
        "id": "nHazBYwGs8k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_roles_prompt(role, objective, limitations, style, query):\n",
        "    \"\"\"Generates a structured prompt based on the R.O.L.E.S. framework.\"\"\"\n",
        "    prompt_template = f\"\"\"\n",
        "    --- INSTRUCTIONS (R.O.L.E.S. FRAMEWORK) ---\n",
        "    ROLE: {role}\n",
        "    OBJECTIVE: {objective}\n",
        "    LIMITATIONS: {limitations}\n",
        "    STYLE: {style}\n",
        "    --- USER QUERY ---\n",
        "    {query}\n",
        "    \"\"\"\n",
        "    return prompt_template\n",
        "\n",
        "# Define a simple chain template for easy switching between models\n",
        "def create_roles_chain(model):\n",
        "    prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
        "    return prompt | model | StrOutputParser()\n",
        "\n",
        "\n",
        "blog_prompt = \"Write a blog post about AI.\"\n",
        "print(\"---  PROMPT (Gemini) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": blog_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQtd91Eno-Ju",
        "outputId": "985bafb4-2ec5-4192-eb86-c078c1b28f69"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---  PROMPT (Gemini) ---\n",
            "## The Rise of the Machines (and Why You Should Care) - A Look at the World of AI\n",
            "\n",
            "Artificial Intelligence. The words themselves conjure images of sentient robots, world domination, and the future we've seen in countless sci-fi movies. But the reality of AI is far more nuanced, complex, and, frankly, already impacting our lives in ways you might not even realize.\n",
            "\n",
            "So, let's dive into the world of AI, demystify some of the jargon, and explore why you should be paying attention.\n",
            "\n",
            "**What Exactly IS AI?**\n",
            "\n",
            "At its core, Artificial Intelligence is about creating machines that can perform tasks that typically require human intelligence. This includes things like:\n",
            "\n",
            "*   **Learning:** The ability to acquire information and improve performance over time.\n",
            "*   **Reasoning:** Using logic and deduction to solve problems.\n",
            "*   **Problem-solving:** Finding solutions to complex challenges.\n",
            "*   **Perception:** Understanding and interpreting the world through senses like sight and sound.\n",
            "*   **Natural Language Processing (NLP):** Understanding and responding to human language.\n",
            "\n",
            "**Beyond the Buzzwords: Real-World Applications**\n",
            "\n",
            "Forget the robots for a moment. AI is already transforming industries and shaping our daily lives:\n",
            "\n",
            "*   **Healthcare:** AI is being used to diagnose diseases, personalize treatments, and accelerate drug discovery. Think of AI-powered imaging that can detect anomalies earlier than the human eye.\n",
            "*   **Finance:** Fraud detection, algorithmic trading, and personalized financial advice are all powered by AI.\n",
            "*   **Retail:** Recommendation engines on e-commerce sites, chatbots for customer service, and optimized supply chains are all examples of AI in action.\n",
            "*   **Transportation:** Self-driving cars are the most visible example, but AI is also improving traffic management and logistics.\n",
            "*   **Entertainment:** From personalized music recommendations to sophisticated video game AI, your entertainment experience is increasingly shaped by algorithms.\n",
            "\n",
            "**The Different Flavors of AI**\n",
            "\n",
            "It's important to understand that AI isn't a monolithic entity. There are different types, each with its own capabilities:\n",
            "\n",
            "*   **Narrow or Weak AI:** This is the most common type, designed to perform a specific task. Think of a spam filter or a voice assistant like Siri or Alexa.\n",
            "*   **General or Strong AI:** This is the hypothetical \"true\" AI that can perform any intellectual task that a human being can. We're not there yet, and it's a subject of much debate.\n",
            "*   **Super AI:** This is a hypothetical AI that surpasses human intelligence in all aspects. This is the realm of science fiction.\n",
            "\n",
            "**The Challenges and the Future**\n",
            "\n",
            "While the potential of AI is immense, there are also challenges we need to address:\n",
            "\n",
            "*   **Bias and Fairness:** AI algorithms are trained on data, and if that data reflects existing biases, the AI will perpetuate them.\n",
            "*   **Job Displacement:** As AI automates tasks, some jobs will be lost. We need to prepare for this shift with retraining programs and new economic models.\n",
            "*   **Ethical Considerations:** We need to develop ethical guidelines for AI development and deployment to ensure it's used responsibly and for the benefit of humanity.\n",
            "*   **Data Privacy:** AI relies on data, and we need to protect our privacy and control how our data is used.\n",
            "\n",
            "**So, What Now?**\n",
            "\n",
            "The future is undeniably intertwined with AI. Here's what you can do:\n",
            "\n",
            "*   **Stay Informed:** Read articles, listen to podcasts, and follow experts in the field.\n",
            "*   **Learn the Basics:** Understand the fundamental concepts of AI and machine learning.\n",
            "*   **Consider the Ethical Implications:** Think about the societal impact of AI and how we can ensure it's used responsibly.\n",
            "*   **Embrace the Change:** Be open to new technologies and the opportunities they create.\n",
            "\n",
            "AI is not just a technological revolution; it's a societal one. By understanding its potential, its challenges, and its impact, we can all play a role in shaping a future where AI benefits everyone. The machines are rising, and it's time to understand them.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- R.O.L.E.S. ENGINEERED PROMPT ---\n",
        "roles_blog_prompt = generate_roles_prompt(\n",
        "    role=\"A seasoned Marketing Director and AI expert.\",\n",
        "    objective=\"Write a compelling, 300-word introduction to the R.O.L.E.S. prompt engineering framework.\",\n",
        "    limitations=\"Maximum 300 words. Must not use the word 'chatbot' or 'AI helper'.\",\n",
        "    style=\"Enthusiastic, engaging, and structured as Markdown with a H2 title.\",\n",
        "    query=\"Write the post now.\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- ENGINEERED PROMPT (Gemini 2.5 Flash) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": roles_blog_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9BG3r_FpoZG",
        "outputId": "fee70d36-b001-43c6-f30d-8fe9970ab1e4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ENGINEERED PROMPT (Gemini 2.5 Flash) ---\n",
            "## Unleash the Power of Language: Introducing R.O.L.E.S.\n",
            "\n",
            "Hello, fellow marketing mavens and tech enthusiasts! Are you ready to revolutionize how you interact with sophisticated language models? We're on the cusp of a new era, and mastering the art of prompt engineering is your key to unlocking unprecedented creative and strategic potential. Forget generic requests; it's time to craft prompts that deliver exceptional results.\n",
            "\n",
            "That's where R.O.L.E.S. comes in. This isn't just another framework; it's your strategic roadmap to crafting prompts that are clear, concise, and command the desired outcome. R.O.L.E.S. provides a structured approach, ensuring you get the most out of these powerful tools.\n",
            "\n",
            "**R**efine your **O**bjective: What exactly do you want to achieve? Be specific!\n",
            "**L**everage **E**xamples: Provide context and guide the model with illustrative examples.\n",
            "**S**pecify the **S**tyle: Define the tone, format, and voice you desire.\n",
            "\n",
            "By systematically applying R.O.L.E.S., you'll move beyond basic requests and into the realm of sophisticated communication. Imagine generating compelling ad copy, crafting engaging social media content, or even brainstorming innovative marketing campaigns – all with unparalleled efficiency and precision.\n",
            "\n",
            "This framework empowers you to become a true master of language, transforming your ideas into tangible results. Get ready to elevate your marketing game and experience the future of content creation! Let's dive in and explore the incredible possibilities that await!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Set 2: Code Review"
      ],
      "metadata": {
        "id": "LVRCjDLAs2u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code_snippet = \"def sum_list(l): total = 0; for i in l: total += i; return total\"\n",
        "\n",
        "\n",
        "# ---  PROMPT TEST ---\n",
        "code_prompt = f\"Fix this code and tell me what is wrong: {code_snippet}\"\n",
        "print(\"--- PROMPT (Gemini 2.5 Flash) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": code_prompt}))\n",
        "\n",
        "\n",
        "# --- R.O.L.E.S. ENGINEERED PROMPT ---\n",
        "roles_code_prompt = generate_roles_prompt(\n",
        "    role=\"A Senior Python Developer specializing in clean, efficient code.\",\n",
        "    objective=\"Refactor the provided code snippet for efficiency (using built-in methods), add a docstring, and identify a single major bug in the logic (if any).\",\n",
        "    limitations=\"Do not change the function name. Output the revised code first, then provide a single paragraph critique.\",\n",
        "    style=\"Formal tone. Output must be in two sections: 'Revised Code' and 'Critique'.\",\n",
        "    query=f\"Here is the code: {code_snippet}\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- ENGINEERED PROMPT (gemini_model) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": roles_code_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHBWWYxRqFs_",
        "outputId": "706a4d48-7706-4290-8966-7ef27fe64b8b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- PROMPT (Gemini 2.5 Flash) ---\n",
            "```python\n",
            "def sum_list(l):\n",
            "  \"\"\"\n",
            "  Calculates the sum of all numbers in a list.\n",
            "\n",
            "  Args:\n",
            "    l: A list of numbers.\n",
            "\n",
            "  Returns:\n",
            "    The sum of the numbers in the list.\n",
            "  \"\"\"\n",
            "  total = 0\n",
            "  for i in l:\n",
            "    total += i\n",
            "  return total\n",
            "```\n",
            "\n",
            "**What was wrong (and why the fix is what it is):**\n",
            "\n",
            "The original code was already correct in its functionality.  It correctly calculates the sum of a list of numbers.  The \"fix\" here is more about best practices and making the code more readable and maintainable.  Here's a breakdown:\n",
            "\n",
            "*   **Docstring:** I added a docstring (the triple-quoted string) to explain what the function does, what arguments it takes, and what it returns.  This is *crucial* for good code documentation.  It helps anyone (including your future self) understand how to use the function.\n",
            "*   **Comments:**  While the original code was simple enough that comments weren't strictly *necessary*, a docstring is always a good idea for clarity.\n",
            "*   **Readability:**  The code was already very readable, but the docstring further enhances understanding.\n",
            "\n",
            "**In summary:** The original code worked perfectly. The \"fix\" focuses on making the code more professional and easier to understand through documentation.  There were no functional errors to correct.\n",
            "\n",
            "\n",
            "--- ENGINEERED PROMPT (gemini_model) ---\n",
            "```python\n",
            "def sum_list(l):\n",
            "    \"\"\"Calculates the sum of all numbers in a list.\n",
            "\n",
            "    Args:\n",
            "        l: A list of numbers (int or float).\n",
            "\n",
            "    Returns:\n",
            "        The sum of the numbers in the input list.\n",
            "    \"\"\"\n",
            "    return sum(l)\n",
            "```\n",
            "\n",
            "Critique: The original code, while functionally correct, is inefficient. The refactored code leverages Python's built-in `sum()` function, which is optimized for this specific task. This approach eliminates the need for manual iteration, resulting in cleaner, more readable, and generally faster code. The original code also lacked a docstring, which has been added to improve code maintainability and understanding. There were no logical bugs in the original code, but the refactoring significantly improves its efficiency.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Set 3: Data Analysis"
      ],
      "metadata": {
        "id": "Q8CkruKBszHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roles_finance_prompt = generate_roles_prompt(\n",
        "    role=\"A highly skeptical Senior Financial Analyst.\",\n",
        "    objective=\"Analyze the past week's fictional performance of AAPL stock based on technical analysis, and make a plausible, short-term prediction.\",\n",
        "    limitations=\"Do not use real-time search. Analysis must be a single paragraph.\",\n",
        "    style=\"Highly technical, formal, and use the term 'stochastic' at least once.\",\n",
        "    query=\"Perform the analysis.\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- ENGINEERED PROMPT (Gemini 2.5 Flash) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": roles_finance_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm2D9DZKqKVh",
        "outputId": "51773137-8c25-40a4-83ee-a13ca9414f63"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ENGINEERED PROMPT (Gemini 2.5 Flash) ---\n",
            "Alright, let's dissect this AAPL charade. The past week's price action, as I interpret it, reveals a rather unconvincing bullish attempt. We've seen a modest rally, but the volume profile suggests a lack of conviction; the buying pressure simply isn't there to sustain a significant move. Key resistance levels, particularly around the 175 mark, remain untested, and the Relative Strength Index (RSI) is hovering precariously near overbought territory, hinting at a potential pullback. Furthermore, the stochastic oscillator is signaling a possible bearish crossover, which, coupled with the weakening momentum, paints a picture of short-term downside risk. My prediction? Expect a consolidation phase, possibly a slight correction, within the next few trading days. I'd advise caution; this rally feels flimsy.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Set 4: Summarization"
      ],
      "metadata": {
        "id": "EXbGlRJDsvye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "long_text = \"\"\"\n",
        "The company, Acme Corp, announced its Q3 earnings on October 15th, reporting a staggering\n",
        "revenue increase of $45 million, surpassing last year's figure of $30 million.\n",
        "The CEO stated that hiring will increase by 20% in the new year, starting January 1st.\n",
        "This growth is primarily attributed to their successful digital marketing campaign launched in July.\n",
        "The stock reacted positively, climbing $5 per share within 48 hours of the announcement.\n",
        "\"\"\"\n",
        "\n",
        "# ---  PROMPT TEST ---\n",
        "bad_summarize_prompt = f\"Summarize this paragraph: {long_text}\"\n",
        "print(\"--- NORMAL PROMPT (gemini_model) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": bad_summarize_prompt}))\n",
        "\n",
        "\n",
        "# --- R.O.L.E.S. ENGINEERED PROMPT ---\n",
        "roles_summarize_prompt = generate_roles_prompt(\n",
        "    role=\"A News Editor reviewing a financial wire report.\",\n",
        "    objective=\"Summarize the text, focusing only on reported dates and financial figures.\",\n",
        "    limitations=\"Must be exactly 2 sentences long. Include no opinion or analysis.\",\n",
        "    style=\"Objective and journalistic.\",\n",
        "    query=f\"Summarize this text: {long_text}\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- ENGINEERED PROMPT (Gemini 2.5 Flash) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": roles_summarize_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdGxDM3Jr6aS",
        "outputId": "8ac4bf3a-bd59-4f11-ad23-6579b349f45e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- NORMAL PROMPT (gemini_model) ---\n",
            "Acme Corp. announced strong Q3 earnings on October 15th, with revenue increasing by $45 million, exceeding last year's. The company attributes this growth to a successful digital marketing campaign and plans to increase hiring by 20% starting January 1st. The positive news led to a $5 per share increase in stock price within two days.\n",
            "\n",
            "\n",
            "--- ENGINEERED PROMPT (Gemini 2.5 Flash) ---\n",
            "Acme Corp reported Q3 earnings on October 15th, with revenue increasing to $45 million, exceeding the previous year's $30 million. Hiring is projected to increase by 20% starting January 1st.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Set 5: Topic Classification"
      ],
      "metadata": {
        "id": "pLJCd0CBsplU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classification_text = \"The latest driver updates fixed the latency issues on the GPU, improving frame rates substantially.\"\n",
        "\n",
        "# --- NORMAL/BAD PROMPT TEST ---\n",
        "bad_classify_prompt = f\"What is this text about: {classification_text}\"\n",
        "print(\"--- BAD PROMPT (Gemini 2.5 Flash) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": bad_classify_prompt}))\n",
        "\n",
        "\n",
        "# --- R.O.L.E.S. ENGINEERED PROMPT (Using Examples for format) ---\n",
        "roles_classify_prompt = generate_roles_prompt(\n",
        "    role=\"A Data Scientist performing classification.\",\n",
        "    objective=\"Classify the following text into one of these categories: [Hardware, Software, Finance].\",\n",
        "    limitations=\"Output must be a single word and case-sensitive (e.g., 'Hardware').\",\n",
        "    style=\"Raw text output. Use the following example:\",\n",
        "    query=f\"\"\"\n",
        "    Example Input: \"The market closed high.\"\n",
        "    Example Output: Finance\n",
        "\n",
        "    Classify this input: \"{classification_text}\"\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- ENGINEERED PROMPT (gemini_model) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": roles_classify_prompt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k654nPazr831",
        "outputId": "630375c2-1d3a-4a78-a297-d580437f3b42"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BAD PROMPT (Gemini 2.5 Flash) ---\n",
            "The text is about **a positive outcome of a driver update for a graphics card (GPU)**. Specifically, it highlights that the update resolved latency problems, leading to a significant improvement in frame rates (performance).\n",
            "\n",
            "\n",
            "--- ENGINEERED PROMPT (gemini_model) ---\n",
            "Software\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Set 6: Sentiment Analysis"
      ],
      "metadata": {
        "id": "P99aZsnisljT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_review = \"The product works exactly as advertised, but the delivery took far too long, making the overall experience frustrating.\"\n",
        "\n",
        "\n",
        "# --- R.O.L.E.S. ENGINEERED PROMPT ---\n",
        "roles_sentiment_prompt = generate_roles_prompt(\n",
        "    role=\"A Customer Service Manager focused on customer feedback.\",\n",
        "    objective=\"Analyze the provided review text to determine overall customer sentiment (Positive, Negative, or Neutral).\",\n",
        "    limitations=\"Only use the exact labels: 'Positive', 'Negative', or 'Neutral'.\",\n",
        "    style=\"Strictly output a JSON object.\",\n",
        "    query=f\"\"\"\n",
        "    Analyze this review: \"{sentiment_review}\"\n",
        "\n",
        "    Required JSON format:\n",
        "    {{\n",
        "      \"sentiment\": \"<LABEL>\",\n",
        "      \"confidence\": \"<1-100 score>\"\n",
        "    }}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n--- ENGINEERED PROMPT (gemini_model) ---\")\n",
        "print(create_roles_chain(gemini_model).invoke({\"input\": roles_sentiment_prompt}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WQwb15msPKZ",
        "outputId": "66b0c6e4-3939-4b73-b2fc-a8ad183962d9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ENGINEERED PROMPT (gemini_model) ---\n",
            "```json\n",
            "{\n",
            "  \"sentiment\": \"Negative\",\n",
            "  \"confidence\": \"85\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZNc81_Vsg2e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
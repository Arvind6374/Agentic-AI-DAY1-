Day 2 â€“ LLM Models, Privacy, Tokenization & Prompting (Simple Notes)
âœ… What I Learned Today
1. Types of LLMs

Closed-Source Models â†’ GPT-4, Gemini

Very powerful

Cost per token

Data privacy risk

Open-Source Models â†’ Llama 3, Mistral, Gamma

Free to run locally

Good for projects with sensitive data

2. PII (Personal Identifiable Information)

Anything that identifies a person
Examples: Aadhaar, biometrics, phone number, address

If data has PII â†’ use local models OR remove PII before sending to API

3. Batch vs Real-Time Processing

Batch â†’ No urgent output
Example: summarizing yesterdayâ€™s 10,000 news articles

Real-Time â†’ Immediate response
Example: travel chatbot answering user questions instantly

4. Cost & Latency

Closed-source models charge based on tokens

Open-source models only need laptop/PC power

Bigger model = slower and needs more hardware

5. Prompt Engineering (ROLES Method)

A simple way to write better prompts:

R â€“ Role â†’ What role should AI take? (teacher, developer, etc.)

O â€“ Objective â†’ What do you want? (write, explain, summarize)

L â€“ Limitations â†’ Word limit / rules

E â€“ Examples â†’ Give sample input-output

S â€“ Style â†’ Format (JSON, table, bullet points)

6. Advanced Prompt Techniques

Chain of Thought â†’ â€œThink step by stepâ€

Self-Consistency â†’ AI gives multiple answers â†’ best one chosen

7. Hands-On Setup

Created PyCharm project with Python 3.12

Added .env file for API key

Installed packages from requirements.txt

Used Ollama to download and test local models (Gamma 3 / Llama 3)

8. Use-Case Examples

Legal Contracts (Sensitive) â†’ Use local models

Travel Chatbot (Public) â†’ Use API models

Large Batch Summaries â†’ Use lightweight open-source models

ğŸ“‚ Tools Used Today

PyCharm

Google Colab

Hugging Face (model details)

Ollama (run local models)
